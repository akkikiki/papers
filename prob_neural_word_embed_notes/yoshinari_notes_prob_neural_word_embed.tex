\documentclass[11pt]{article}
\usepackage[letterpaper,margin=1in]{geometry}
\usepackage{amsbsy}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{url}

\newcommand{\argmax}{\mathop{\rm arg~max}\limits}

\begin{document}

\section{Summary}

This is a note for \cite{bhatia-guthrie-eisenstein:2016:EMNLP2016}.
The implementation code for this paper can be found at \footnote{\url{https://github.com/rguthrie3/MorphologicalPriorsForWordEmbeddings}}.

The important components are as follows:
\begin{enumerate}
 \item RNN language model
 \item Morphological priors
 \item Latent word embedding $b_w$.
 \item Morpheme emebedding $u_m$.
\end{enumerate}


$$
Bernouli()
$$

\bibliographystyle{plain}
\bibliography{yoshinari_notes_prob_neural_word_embed}

\end{document}

