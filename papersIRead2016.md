# Deep Learning
[Long Short-Term Meomory Neural Networks, EMNLP 2015](http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP141.pdf)
* Uses 3 NNs 1) character embeddings, 2) LSTM, and 3) tag inference.
* Takes 3 days to train on PKU dataset using CPU without any optimization.
* A code implemented by another person is [here](https://github.com/dalstonChen/CWS_LSTM) but I have not checked if this implementation is correct or not.

# Topic Models
[Sparse Additive Generative Models of Text, ICML 2011](http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Eisenstein_534.pdf)
* Require less variables. (E.g. switching variables in topic-perspective models in Ahmed & Xing 2010)
